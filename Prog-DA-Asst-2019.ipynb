{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Analysis Assignment 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ref:\n",
    "- Location: C:\\Users\\35386\\Desktop\\Prog-DA-Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Overall Purpose of the Package.\n",
    "- Ref: https://jupyter.org/\n",
    "- 'Project Jupyter exists to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages.'\n",
    "- It's default entry mode is 'code', and at its very basic, this will run programs like any other integrated Development Environment, such as the ipython interpereter. Its main advantage however, as outlined above, is that it interacts with other programming langugaes and it is very useful for investigating Datasets. \n",
    "- It has 3 main types of cells. The Mark down cell which we are currently in displays trxt as HTML.\n",
    "- The second is the Code cell, that accepts code, the following is an example of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50\n"
     ]
    }
   ],
   "source": [
    "a = 100\n",
    "b = 50\n",
    "print (b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cell above, is an output cell, that gives the output of the code cell. Double clicking on this will hide it.\n",
    "- There are a number of other keyboard shortcuts available in the help menu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages\n",
    "- Ref: https://www.analyticsvidhya.com/blog/2018/05/starters-guide-jupyter-notebook/\n",
    "\n",
    "- Jupyter Notebook is an open-source web application that allows us to create and share codes and documents.\n",
    "\n",
    "- It provides an environment, where you can document your code, run it, look at the outcome, visualize data and see the results without leaving the environment. This makes it a handy tool for performing end to end data science workflows – data cleaning, statistical modeling, building and training machine learning models, visualizing data, and many, many other uses.\n",
    "\n",
    "- Jupyter Notebooks really shine when you are still in the prototyping phase. This is because your code is written in indepedent cells, which are executed individually. This allows the user to test a specific block of code in a project without having to execute the code from the start of the script. Many other IDE enviornments (like RStudio) also do this in several ways, but I have personally found Jupyter’s individual cells structure to be the best of the lot. \n",
    "- Jupyter Notebooks are incredibly flexible, interactive and powerful tools in the hands of a data scientist. They even allow you to run other languages besides Python, like R, SQL, etc. Since they are more interactive than an IDE platform, they are widely used to display codes in a more pedagogical manner.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disadvantages\n",
    "- Ref: https://towardsdatascience.com/5-reasons-why-jupyter-notebooks-suck-4dc201e27086\n",
    "- 1. It is almost impossible to enable good code versioning\n",
    "- Do you work in a data team that collaborates and might work on the same notebooks? Probably you then tried to merge two jupyter notebooks. Due to the fact that jupyter notebooks are stored as big JSON files merging two notebooks is virtually impossible. This is bad because we cannot apply tools for software teams like a good git workflow will pull requests and reviews.\n",
    "- 2. There is no IDE integration, no linting, no code-style correction\n",
    "- Once I posted a snippet from a jupyter notebook into slack python developer group. I cannot say how ashamed I felt about the way they blamed me for not following pep conventions. Jupyter has no kind of linting meaning you can write very badly styled coded. Just try to copy your code into your favorable code editor with linting, and you will see what I mean. Data Scientist are not software engineers and therefore tools that govern their code quality and help to improve it are very important.\n",
    "- 3. Very hard to test\n",
    "- A colleague of mine once said when you work with jupyter notebooks you basically forget software engineering. And he is right! It is so damn hard to structure your code reasonable, put your code into functions and then develop tests for them. I’m a huge fan of test-driven development and I can only recommend moving away as quickly as possible from jupyter notebooks when you develop serious data pipelines. Jupyter notebooks are a tool for exploration not for production, as soon as you want to reproduce some experiments and run notebooks frequently. Dump your jupyter notebooks and develop your python script based on test-driven-development principles. (And yes you can also develop data products using TDD, you just need to get your fixtures right!)\n",
    "- 4. The non-linear workflow of jupyter\n",
    "- Did you ever destroy your current working state when jumping between cells of jupyter notebooks? Yes? I can tell you’re not alone this happens to me quite frequently. This way of jumping around between cells can result in unreproducible experiments. The interactive way of coding and jumping in a notebook between cells is both one of jupyter notebooks best features and its biggest weakness.\n",
    "- 5. Jupyter is bad for running long asynchronous tasks\n",
    "- I like to say big data means big problems. Usually, you start when approaching a problem with a small dataset that fits into your memory. You will come to the point where your machine is not good enough anymore. You could then jump to tools like spark, dask and distributed and run them from your notebook. I suggest not to do so. If you got your first data exploration done and want to rum large-scale experiments or even finalize your data pipeline. Pull your code out of the jupyter notebook start a proper python project, create fixtures, write tests and deploy your application then to a cluster. This will help you a lot to build reliable data-driven products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Random Data function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ref: https://www.investopedia.com/terms/s/simple-random-sample.asp\n",
    "- \"A simple random sample is a subset of a statistical population in which each member of the subset has an equal probability of being chosen. A simple random sample is meant to be an unbiased representation of a group\". In numpy, the Random sampling provides ten data functions from which random numbers can be drawn. Each of the data functions has specific peramiters that will impact the range from which the random sample (or subset can be drawn. \n",
    "- Simple Randon Data is a subpackage of numpy and is therefore can be imported into juypter notebook. \n",
    "- Ref: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutations Function\n",
    "- Ref: https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.permutation.html\n",
    "- The permutation function in numpy is called by giving the command numpy.random.permutation(x) or numpy.random.shuffle (x).\n",
    "- In numpy.random.permutation(x) gives as an output a randomly permutation of a sequence or a permutation of a range. \n",
    "- In numpy.random.shuffle(x) the sequence is modified by shuffling its content in palce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://github.com/numpy/numpy/issues/8250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "A = np.random.permutation([2, 3, 5, 7, 11])\n",
    "B = np.random.permutation (N)\n",
    "c = np.arange(12).reshape(3,4)\n",
    "D = np.arange(12).reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  7  2 11  3]\n"
     ]
    }
   ],
   "source": [
    "print (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4 2 7 8 5 6 1 9]\n"
     ]
    }
   ],
   "source": [
    "print (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "print (c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ((np.random.permutation(c)))\n",
    "(np.random.permutation(c))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "print (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "print (D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9, 10, 11],\n",
       "       [ 6,  7,  8],\n",
       "       [ 0,  1,  2],\n",
       "       [ 3,  4,  5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (np.random.shuffle(D))\n",
    "np.random.shuffle(D)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One of the difference noted here is how each function is called, in shuffle using print outputs None. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
